{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Desafio 4 - Trabajo Final</h2>\n",
    "\n",
    "<h3>Grupo 7</h3>\n",
    "<ul>\n",
    "    <li>Ignacio Mendieta</li>\n",
    "    <li>Laura Jazmín Chao</li>\n",
    "    <li>Juan Nicolás Capistrano</li>\n",
    "    <li>Betiana Srur</li>\n",
    "    <li>Marecelo Carrizo</li>\n",
    "    \n",
    "</ul>\n",
    "<h3>Disponibilización de modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_toc\"></a> \n",
    "<h2> Tabla de Contenidos </h2>\n",
    "\n",
    "[Librerías](#section_import)\n",
    "\n",
    "[Entrenamiento del model](#section_train)\n",
    "\n",
    "[Visualización de coeficientes](#section_coef)\n",
    "\n",
    "[Solicitud de predicción](#section_predict)\n",
    "\n",
    "[Disponibilización del servidor](#section_server)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_import\"></a> \n",
    "<h3>Librerías</h3>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import numpy as np\n",
    "#from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "#import statsmodels.api as sm\n",
    "#import statsmodels.formula.api as smf\n",
    "#import statsmodels.tsa.api as smt\n",
    "\n",
    "#from scipy import stats\n",
    "#from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from flask import  Flask, request, jsonify, render_template\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_train\"></a> \n",
    "<h3>Entrenamiento del modelo</h3>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciamos nuestra API\n",
    "app = Flask('Emision de CO2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos el modelo\n",
    "\n",
    "@app.route('/entrenar_modelo',methods=['POST'])\n",
    "def entrenar_modelo():\n",
    "    \n",
    "    # la función \"request.get_json\" de Flask para capturar la información que le envíemos a la API\n",
    "    data = request.get_json(force=True)\n",
    "    \n",
    "    # Separamos la información de data y usamos json.loads() para transformar el dataframe que está en formato\n",
    "    # json a un diccionario y luego lo convertimos en un DataFrame.\n",
    "    df=pd.DataFrame(json.loads(data['base']))\n",
    "    columns_name=data['lista_predictores']\n",
    "    target_name=data['target']\n",
    "    directorio_modelo=data['directory']\n",
    "    nombre_modelo=data['name']\n",
    "        \n",
    "    # Separamos las \"X\" y la \"y\" para entrenar nuestro modelo\n",
    "    X = df[columns_name]\n",
    "    y = df[target_name]\n",
    "    \n",
    "    # Hacemos el train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, random_state=40)\n",
    "    \n",
    "    # Instaciamos el modelo de regresion Lineal.\n",
    "    modelo = LinearRegression()\n",
    "    \n",
    "    # Entrenamos el modelo \n",
    "    modelo.fit(X_train, y_train)\n",
    "        \n",
    "    # Evaluamos el R2 de train y de test\n",
    "    result_train=r2_score(y_train,modelo.predict(X_train))\n",
    "    result_test=r2_score(y_test,modelo.predict(X_test))\n",
    "        \n",
    "    # Guardamos el modelo entrenado en una carpeta que se llama \"modelos\" que esté a la misma altura que la notebook\n",
    "    dir_=directorio_modelo+'/'+nombre_modelo+'.pkl'\n",
    "    with open(dir_, 'wb') as modelo_pkl:\n",
    "        pickle.dump(modelo, modelo_pkl)\n",
    "       \n",
    "    \n",
    "    # La función devuelva el alpha elegido por el modelo, el resultado de train y el de test.\n",
    "    return jsonify({'r2_resultado_train':float(result_train), 'r2_resultado_test':float(result_test)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_coef\"></a> \n",
    "<h3>Visualización de Coeficientes</h3>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciamos nuestro segunda función asociada a su endpoint. Usamos el método POST ya que vamos a enviar información\n",
    "# al servidor: la figura con los coeficientes de nuestro modelo entrenado\n",
    "@app.route('/plot_coeficientes',methods=['POST'])\n",
    "def plotear_coeficientes():\n",
    "    \n",
    "    # la función \"request.get_json\" de Flask para capturar la información que le envíemos a la API\n",
    "    data = request.get_json(force=True)\n",
    "    \n",
    "    # Separamos la información de data.\n",
    "    direccion=data['direccion']\n",
    "    name_modelo=data['nombre_modelo']\n",
    "    colores=data['paleta_colores']\n",
    "    size=data['tamano']\n",
    "    predictores=data['predictores']\n",
    "    \n",
    "    # Levantamos el modelo que tenemos grabado en disco con el llamado anterior\n",
    "    # (hay que tener en cuenta que tenemos que hacer el llamado anterior primero cuando estemos en la notebook\n",
    "    # que simula ser el cliente).\n",
    "    dir_input=direccion+'/'+name_modelo+'.pkl'\n",
    "    with open(dir_input, 'rb') as modelo_pkl:\n",
    "        modelo_load = pickle.load(modelo_pkl)\n",
    "        \n",
    "    # Levantamos los coeficientes ya calculados del modelo\n",
    "    # Los ponemos en un dataframe junto con el nombre de los predictores.\n",
    "    # Pasamos los coeficientes a valores absolutos y los ordenamos de mayor a \n",
    "    # menor para hacer el gráfico.\n",
    "    coef=abs(pd.DataFrame({'coeficientes':modelo_load.coef_},index=predictores)).\\\n",
    "                           sort_values(by='coeficientes',ascending=False)\n",
    "    \n",
    "    \n",
    "    # Generamos la figura y la guardamos\n",
    "    fig, ((ax1)) = plt.subplots(1,1,gridspec_kw={'hspace': 0.45, 'wspace': 0.15},figsize=size)\n",
    "    fig.suptitle(\"Coeficientes\",y=0.96,x=0.135,fontsize=24,fontweight='bold')\n",
    "\n",
    "    ax1 = sns.barplot(x=\"index\", y=\"coeficientes\", data=coef.reset_index(),ax=ax1,palette=colores)\n",
    "    ax1.xaxis.set_label_text('Coeficientes')\n",
    "    ax1.yaxis.set_label_text('Valores coeficientes')\n",
    "    plt.close(); #usamos esta línea para que la figura no se imprima en pantalla\n",
    "    \n",
    "    # guardamos la figura donde se guardan los modelos\n",
    "    dir_figura=direccion+'/'+name_modelo+'.jpg'\n",
    "    fig.savefig(dir_figura,dpi=150)\n",
    "    \n",
    "    # devolvemos un json con los coeficientes. Dado que las API devuelven la información en formato\n",
    "    # json, usamos el método de los dataframes \".to_json()\" para poder retornar los datos de los\n",
    "    # coeficientes.\n",
    "    return jsonify(coef.to_json())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_predict\"></a> \n",
    "<h3>Solicitud de predicción</h3>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dado que en este endopint no vamos a guardar nada en el servidor, sino recibir información, usamos \n",
    "# el método GET. \n",
    "@app.route(\"/prediccion\",methods=['GET'])\n",
    "def predecir_consumo_co2():\n",
    "    \n",
    "    # Usamos request.args para tomar las query que le pasamos a la URL\n",
    "    direccion=request.args['direccion']\n",
    "    name_modelo=request.args['nombre_modelo']\n",
    "    caso_to_predict=request.args['features']\n",
    "    \n",
    "    # Levantamos el modelo y el escalador que ya tenemos entrenado\n",
    "    with open(direccion+'/'+name_modelo+'.pkl', 'rb') as modelo_pkl:\n",
    "        modelo_load = pickle.load(modelo_pkl)\n",
    "        \n",
    "    # re-escalamos los datos con el escalador entrenado (tengan en cuenta que el escalador va a estar\n",
    "    # esperando una estructura como un DataFrame)\n",
    "    \n",
    "    #scaled_case=scaler_load.transform(pd.DataFrame(json.loads(caso_to_predict),index=[0]))\n",
    "    \n",
    "    # realizamos la prediccion\n",
    "    prediccion=modelo_load.predict(pd.DataFrame(json.loads(caso_to_predict),index=[0]))\n",
    "    \n",
    "    return jsonify({'prediccion_co2':float(prediccion)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_server\"></a> \n",
    "<h3>Disponibilización del servidor</h3>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora ejecutamos esta línea de código que pone a disposición los tres endpoints que armamos arriba. \n",
    "# Es hora de ir a la otra notebook en la que simulamos ser un cliente y hacer los llamadados para cada\n",
    "# uno de estos tres endopoints...\n",
    "app.run(host='0.0.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
