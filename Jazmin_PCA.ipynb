{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # settings colab:\n",
    "    import google.colab\n",
    "except ModuleNotFoundError:    \n",
    "    # settings local:\n",
    "    %run \"../../../common/0_notebooks_base_setup.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<img src='../../../common/logo_DH.png' align='left' width=35%/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "El dataset tiene información sobre propiedades en Boston. El objetivo es predecir el precio de estas propiedades.\n",
    "\n",
    "https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data\n",
    "\n",
    "http://jse.amstat.org/v19n3/decock.pdf\n",
    "\n",
    "Para ver la descripción de los campos que componen este dataset:\n",
    "<a href=\"../Data/data_description.txt\">data_description</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema\n",
    "\n",
    "Transformando las variables del dataset de propiedades en Boston usando StandardScaler y OneHotEncoding, vamos a estimar los valores del campo `SalePrice` usando modelos de regresión lineal.\n",
    "\n",
    "Después, vamos a comparar los resultados de las predicciones de estos modelos con los que obtenemos usando como variables explicativas la proyección en las componentes principales del dataset transformado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1 - Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/emision-co2-autos_limpio.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vehiculo_marca</th>\n",
       "      <th>vehiculo_modelo</th>\n",
       "      <th>vehiculo_tipo</th>\n",
       "      <th>vehiculo_traccion</th>\n",
       "      <th>vehiculo_id_motor</th>\n",
       "      <th>vehiculo_cilindrada</th>\n",
       "      <th>vehiculo_potencia</th>\n",
       "      <th>vehiculo_tipo_transmision</th>\n",
       "      <th>vehiculo_tipo_combustible</th>\n",
       "      <th>vehiculo_standard_emision</th>\n",
       "      <th>lca_numero</th>\n",
       "      <th>fecha_firma</th>\n",
       "      <th>ensayo_gei_numero</th>\n",
       "      <th>ensayo_gei_laboratorio</th>\n",
       "      <th>emision_CO2</th>\n",
       "      <th>consumo_urbano</th>\n",
       "      <th>consumo_extraurbano</th>\n",
       "      <th>consumo_mixto</th>\n",
       "      <th>id_etiqueta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TOYOTA</td>\n",
       "      <td>LAND CRUISER 200</td>\n",
       "      <td>SUV</td>\n",
       "      <td>4x4</td>\n",
       "      <td>TOYOTA 1VD-FTV</td>\n",
       "      <td>4461.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AUTOMATICA</td>\n",
       "      <td>GAS OIL</td>\n",
       "      <td>EURO V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04/10/2017</td>\n",
       "      <td>H1860666086/241</td>\n",
       "      <td>VINÇOTTE nv</td>\n",
       "      <td>260.70</td>\n",
       "      <td>11.56</td>\n",
       "      <td>8.94</td>\n",
       "      <td>9.90</td>\n",
       "      <td>000001A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RENAULT</td>\n",
       "      <td>FLUENCE 2.0 16V</td>\n",
       "      <td>SEDÁN 4 PUERTAS</td>\n",
       "      <td>4x2</td>\n",
       "      <td>RENAULT M4RK7</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CVT</td>\n",
       "      <td>NAFTA</td>\n",
       "      <td>EURO V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22/06/2016</td>\n",
       "      <td>09/09790</td>\n",
       "      <td>UTAC</td>\n",
       "      <td>175.40</td>\n",
       "      <td>10.50</td>\n",
       "      <td>6.10</td>\n",
       "      <td>7.70</td>\n",
       "      <td>000178A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RENAULT</td>\n",
       "      <td>DUSTER 2.0 16v</td>\n",
       "      <td>SEDÁN 5 PUERTAS</td>\n",
       "      <td>4x2</td>\n",
       "      <td>RENAULT F4R E4</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>105</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>NAFTA</td>\n",
       "      <td>EURO V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R1-0210/17</td>\n",
       "      <td>DELPHI</td>\n",
       "      <td>198.86</td>\n",
       "      <td>11.13</td>\n",
       "      <td>6.98</td>\n",
       "      <td>8.52</td>\n",
       "      <td>000650C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RENAULT</td>\n",
       "      <td>DUSTER 2.0 16v 4X4</td>\n",
       "      <td>SEDÁN 5 PUERTAS</td>\n",
       "      <td>4x4</td>\n",
       "      <td>RENAULT F4R E4</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>105</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>NAFTA</td>\n",
       "      <td>EURO V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R1-0209/17</td>\n",
       "      <td>DELPHI</td>\n",
       "      <td>199.74</td>\n",
       "      <td>11.20</td>\n",
       "      <td>7.01</td>\n",
       "      <td>8.55</td>\n",
       "      <td>000659C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CITROËN</td>\n",
       "      <td>DS4</td>\n",
       "      <td>COUPÉ 3 + 2 PUERTAS</td>\n",
       "      <td>4x2</td>\n",
       "      <td>CITROËN EP6CDTM (5FM)</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AUTOMATICA</td>\n",
       "      <td>NAFTA</td>\n",
       "      <td>EURO V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/10/2011</td>\n",
       "      <td>11/04511</td>\n",
       "      <td>UTAC</td>\n",
       "      <td>177.60</td>\n",
       "      <td>10.60</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7.70</td>\n",
       "      <td>000106A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  vehiculo_marca     vehiculo_modelo        vehiculo_tipo vehiculo_traccion  \\\n",
       "0         TOYOTA    LAND CRUISER 200                  SUV               4x4   \n",
       "1        RENAULT     FLUENCE 2.0 16V      SEDÁN 4 PUERTAS               4x2   \n",
       "2        RENAULT      DUSTER 2.0 16v      SEDÁN 5 PUERTAS               4x2   \n",
       "3        RENAULT  DUSTER 2.0 16v 4X4      SEDÁN 5 PUERTAS               4x4   \n",
       "4        CITROËN                 DS4  COUPÉ 3 + 2 PUERTAS               4x2   \n",
       "\n",
       "       vehiculo_id_motor  vehiculo_cilindrada vehiculo_potencia  \\\n",
       "0         TOYOTA 1VD-FTV               4461.0               NaN   \n",
       "1          RENAULT M4RK7               1997.0               NaN   \n",
       "2         RENAULT F4R E4               1998.0               105   \n",
       "3         RENAULT F4R E4               1998.0               105   \n",
       "4  CITROËN EP6CDTM (5FM)               1598.0               NaN   \n",
       "\n",
       "  vehiculo_tipo_transmision vehiculo_tipo_combustible  \\\n",
       "0                AUTOMATICA                   GAS OIL   \n",
       "1                       CVT                     NAFTA   \n",
       "2                    MANUAL                     NAFTA   \n",
       "3                    MANUAL                     NAFTA   \n",
       "4                AUTOMATICA                     NAFTA   \n",
       "\n",
       "  vehiculo_standard_emision  lca_numero fecha_firma ensayo_gei_numero  \\\n",
       "0                    EURO V         NaN  04/10/2017   H1860666086/241   \n",
       "1                    EURO V         NaN  22/06/2016          09/09790   \n",
       "2                    EURO V         NaN         NaN        R1-0210/17   \n",
       "3                    EURO V         NaN         NaN        R1-0209/17   \n",
       "4                    EURO V         NaN  11/10/2011          11/04511   \n",
       "\n",
       "  ensayo_gei_laboratorio  emision_CO2  consumo_urbano  consumo_extraurbano  \\\n",
       "0            VINÇOTTE nv       260.70           11.56                 8.94   \n",
       "1                   UTAC       175.40           10.50                 6.10   \n",
       "2                 DELPHI       198.86           11.13                 6.98   \n",
       "3                 DELPHI       199.74           11.20                 7.01   \n",
       "4                   UTAC       177.60           10.60                 6.00   \n",
       "\n",
       "   consumo_mixto id_etiqueta  \n",
       "0           9.90     000001A  \n",
       "1           7.70     000178A  \n",
       "2           8.52     000650C  \n",
       "3           8.55     000659C  \n",
       "4           7.70     000106A  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['vehiculo_potencia','lca_numero', 'vehiculo_id_motor','vehiculo_id_motor','fecha_firma','ensayo_gei_numero','ensayo_gei_laboratorio','id_etiqueta'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vehiculo_marca</th>\n",
       "      <th>vehiculo_modelo</th>\n",
       "      <th>vehiculo_tipo</th>\n",
       "      <th>vehiculo_traccion</th>\n",
       "      <th>vehiculo_cilindrada</th>\n",
       "      <th>vehiculo_tipo_transmision</th>\n",
       "      <th>vehiculo_tipo_combustible</th>\n",
       "      <th>vehiculo_standard_emision</th>\n",
       "      <th>emision_CO2</th>\n",
       "      <th>consumo_urbano</th>\n",
       "      <th>consumo_extraurbano</th>\n",
       "      <th>consumo_mixto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TOYOTA</td>\n",
       "      <td>LAND CRUISER 200</td>\n",
       "      <td>SUV</td>\n",
       "      <td>4x4</td>\n",
       "      <td>4461.0</td>\n",
       "      <td>AUTOMATICA</td>\n",
       "      <td>GAS OIL</td>\n",
       "      <td>EURO V</td>\n",
       "      <td>260.70</td>\n",
       "      <td>11.56</td>\n",
       "      <td>8.94</td>\n",
       "      <td>9.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RENAULT</td>\n",
       "      <td>FLUENCE 2.0 16V</td>\n",
       "      <td>SEDÁN 4 PUERTAS</td>\n",
       "      <td>4x2</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>CVT</td>\n",
       "      <td>NAFTA</td>\n",
       "      <td>EURO V</td>\n",
       "      <td>175.40</td>\n",
       "      <td>10.50</td>\n",
       "      <td>6.10</td>\n",
       "      <td>7.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RENAULT</td>\n",
       "      <td>DUSTER 2.0 16v</td>\n",
       "      <td>SEDÁN 5 PUERTAS</td>\n",
       "      <td>4x2</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>NAFTA</td>\n",
       "      <td>EURO V</td>\n",
       "      <td>198.86</td>\n",
       "      <td>11.13</td>\n",
       "      <td>6.98</td>\n",
       "      <td>8.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RENAULT</td>\n",
       "      <td>DUSTER 2.0 16v 4X4</td>\n",
       "      <td>SEDÁN 5 PUERTAS</td>\n",
       "      <td>4x4</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>NAFTA</td>\n",
       "      <td>EURO V</td>\n",
       "      <td>199.74</td>\n",
       "      <td>11.20</td>\n",
       "      <td>7.01</td>\n",
       "      <td>8.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CITROËN</td>\n",
       "      <td>DS4</td>\n",
       "      <td>COUPÉ 3 + 2 PUERTAS</td>\n",
       "      <td>4x2</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>AUTOMATICA</td>\n",
       "      <td>NAFTA</td>\n",
       "      <td>EURO V</td>\n",
       "      <td>177.60</td>\n",
       "      <td>10.60</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  vehiculo_marca     vehiculo_modelo        vehiculo_tipo vehiculo_traccion  \\\n",
       "0         TOYOTA    LAND CRUISER 200                  SUV               4x4   \n",
       "1        RENAULT     FLUENCE 2.0 16V      SEDÁN 4 PUERTAS               4x2   \n",
       "2        RENAULT      DUSTER 2.0 16v      SEDÁN 5 PUERTAS               4x2   \n",
       "3        RENAULT  DUSTER 2.0 16v 4X4      SEDÁN 5 PUERTAS               4x4   \n",
       "4        CITROËN                 DS4  COUPÉ 3 + 2 PUERTAS               4x2   \n",
       "\n",
       "   vehiculo_cilindrada vehiculo_tipo_transmision vehiculo_tipo_combustible  \\\n",
       "0               4461.0                AUTOMATICA                   GAS OIL   \n",
       "1               1997.0                       CVT                     NAFTA   \n",
       "2               1998.0                    MANUAL                     NAFTA   \n",
       "3               1998.0                    MANUAL                     NAFTA   \n",
       "4               1598.0                AUTOMATICA                     NAFTA   \n",
       "\n",
       "  vehiculo_standard_emision  emision_CO2  consumo_urbano  consumo_extraurbano  \\\n",
       "0                    EURO V       260.70           11.56                 8.94   \n",
       "1                    EURO V       175.40           10.50                 6.10   \n",
       "2                    EURO V       198.86           11.13                 6.98   \n",
       "3                    EURO V       199.74           11.20                 7.01   \n",
       "4                    EURO V       177.60           10.60                 6.00   \n",
       "\n",
       "   consumo_mixto  \n",
       "0           9.90  \n",
       "1           7.70  \n",
       "2           8.52  \n",
       "3           8.55  \n",
       "4           7.70  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data[\"emisionCo2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2 - Categorical y Non-categorical \n",
    "\n",
    "**2.1** Determinemos qué variables que forman el dataset son categóricas. Consideremos categóricas variables numéricas que tienen como máximo cinco valores distintos.\n",
    "\n",
    "**2.2** Usemos `pandas.Series.astype` para convertir esas nuevas columnas categóricas en `numpy.object`\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Categorical.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [col for col in data.columns if data[col].dtypes == 'object']\n",
    "#categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_categorical_columns = [col for col in data.columns if data[col].dtypes != 'object']\n",
    "\n",
    "print(\"non categorical inicial: \" + str(len(non_categorical_columns)))\n",
    "print(\"categorical inicial: \" + str(len(categorical_columns)))\n",
    "\n",
    "non_categorical_columns_clean = []\n",
    "new_categorical_columns = []\n",
    "\n",
    "for col in non_categorical_columns:\n",
    "    values = data[col].value_counts()\n",
    "    if len(values) <= 5:\n",
    "        categorical_columns.append(col)\n",
    "        new_categorical_columns.append(col)\n",
    "    else:\n",
    "        non_categorical_columns_clean.append(col)\n",
    "\n",
    "\n",
    "print(\"non categorical final: \" + str(len(non_categorical_columns_clean)))\n",
    "print(\"categorical final: \" + str(len(categorical_columns)))\n",
    "print(new_categorical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos los valores que tienen las variables numéricas que consideramos categóricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in new_categorical_columns:\n",
    "    print(col)\n",
    "    print(data[col].value_counts())\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las nuevas columnas categóricas están en la variable `new_categorical_columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[new_categorical_columns] = data[new_categorical_columns].astype(np.object)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3 - Valores nulos\n",
    "\n",
    "Calculemos el porcentaje de nulos en cada columna.\n",
    "\n",
    "Eliminemos aquellas columnas que tengan al menos el 40% de los registros con valores nulos.\n",
    "\n",
    "Eliminemos aquellos registros que tengan al menos un valor nulo en las columnas que no fueron eliminadas en el paso anterior.\n",
    "\n",
    "Eliminemos la columna `Id` del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tam de los datos originales:\n",
    "print(data.shape)\n",
    "nans = pd.isnull(data).sum() / data.shape[0]\n",
    "columns_to_drop = nans[nans > 0.4]\n",
    "# columnas a dropear y porcentaje de nulos\n",
    "print(columns_to_drop)\n",
    "column_names = columns_to_drop.index\n",
    "print(column_names)\n",
    "for column_name in column_names:\n",
    "    data=data.drop(column_name, 1)\n",
    "# tam de los datos después de dropear columnas:\n",
    "print(data.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html\n",
    "\n",
    "print(data.shape)\n",
    "data_complete = data.dropna(axis=0, how='any')\n",
    "print(data_complete.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_complete = data_complete.drop('Id', axis = 'columns')\n",
    "data_complete.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4 - Train test sets\n",
    "\n",
    "Dividamos el dataset de registros completos en 70-30 train test, definiendo como X_train, X_test las matrices de features e Y_train, Y_test los vectores target.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_complete.drop('SalePrice', axis = 1)\n",
    "Y = data_complete[['SalePrice']]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 1237)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5 - Feature engineering\n",
    "\n",
    "**5.1** Usemos one hot encoding para transformar las variables categóricas de los dataset de train y test\n",
    "\n",
    "**5.2** Usemos StandardScaler para transformar las variables numéricas de los dataset de train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1\n",
    "\n",
    "# recalculo categorical_columns porque hay algunas columnas que fueron dropeadas por % de nulos:\n",
    "categorical_columns = [col for col in data_complete.columns if data[col].dtypes == 'object']\n",
    "\n",
    "encoder_categories = []\n",
    "\n",
    "for col in categorical_columns:    \n",
    "    col_categories = data_complete[col].unique()\n",
    "    encoder_categories.append(col_categories)\n",
    "\n",
    "#encoder_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(categories = encoder_categories, sparse=False)\n",
    "\n",
    "encoder = encoder.fit(X_train[categorical_columns])\n",
    "    \n",
    "X_train_encoded = encoder.transform(X_train[categorical_columns])\n",
    "X_train_categorical = pd.DataFrame(X_train_encoded, columns = encoder.get_feature_names(categorical_columns))\n",
    "#X_train_categorical.sample(5)\n",
    "\n",
    "X_test_encoded = encoder.transform(X_test[categorical_columns])\n",
    "X_test_categorical = pd.DataFrame(X_test_encoded, columns = encoder.get_feature_names(categorical_columns))\n",
    "X_test_categorical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2\n",
    "\n",
    "non_categorical_columns = [col for col in X_train.columns if col not in categorical_columns]\n",
    "non_categorical_columns\n",
    "\n",
    "std_sclr = StandardScaler()\n",
    "std_sclr_trained = std_sclr.fit(X_train[non_categorical_columns])\n",
    "X_train_numerical = std_sclr_trained.transform(X_train[non_categorical_columns])\n",
    "X_train_numerical_scaled = pd.DataFrame(X_train_numerical, columns = non_categorical_columns)\n",
    "X_train_numerical_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_numerical = std_sclr_trained.transform(X_test[non_categorical_columns])\n",
    "X_test_numerical_scaled = pd.DataFrame(X_test_numerical, columns = non_categorical_columns)\n",
    "X_test_numerical_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_sclr_target = StandardScaler()\n",
    "std_sclr_target_trained = std_sclr_target.fit(Y_train)\n",
    "Y_train_numerical = std_sclr_target_trained.transform(Y_train)\n",
    "#Y_train_numerical\n",
    "\n",
    "Y_test_numerical = std_sclr_target_trained.transform(Y_test)\n",
    "#Y_test_numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transf = pd.concat([X_train_categorical, X_train_numerical_scaled], axis = 1)\n",
    "print(X_train_categorical.shape)\n",
    "print(X_train_numerical_scaled.shape)\n",
    "print(X_train_transf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transf = pd.concat([X_test_categorical, X_test_numerical_scaled], axis = 1)\n",
    "print(X_test_categorical.shape)\n",
    "print(X_test_numerical_scaled.shape)\n",
    "print(X_test_transf.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 6 - Regresión lineal\n",
    "\n",
    "**6.1** Constuyamos un modelo de regresión lineal múltiple sobre los datasets de train y test transformados.\n",
    "\n",
    "**6.2** Construyamos otro modelo usando regularización Lasso\n",
    "\n",
    "**6.2** Construyamos un terecer modelo usando regularización Ridge\n",
    "\n",
    "Para los tres modelos calculemos:\n",
    "* mean_absolute_error\n",
    "* mean_squared_error\n",
    "* raiz cuadrada de mean_squared_error\n",
    "* r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = linear_model.LinearRegression()\n",
    "linreg.fit(X_train_transf, Y_train_numerical)\n",
    "Y_pred = linreg.predict(X_test_transf)\n",
    "\n",
    "true_values = Y_test_numerical\n",
    "predicted_values = Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_metrics = pd.Series([\n",
    "                metrics.mean_absolute_error(true_values, predicted_values), \n",
    "                metrics.mean_squared_error(true_values, predicted_values),\n",
    "                np.sqrt(metrics.mean_squared_error(true_values, predicted_values)),\n",
    "                metrics.r2_score(true_values, predicted_values)])\n",
    "\n",
    "\n",
    "reg_metrics.index = ['Mean Absolute Error:', 'Mean Squared Error:', 'RMSE:', 'R2:']\n",
    "\n",
    "print(reg_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularización Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = linear_model.Lasso(alpha=0.1)\n",
    "lasso.fit(X_train_transf, Y_train_numerical)\n",
    "Y_pred = lasso.predict(X_test_transf)\n",
    "\n",
    "true_values = Y_test_numerical\n",
    "predicted_values = Y_pred\n",
    "\n",
    "lasso_metrics = pd.Series([\n",
    "                metrics.mean_absolute_error(true_values, predicted_values), \n",
    "                metrics.mean_squared_error(true_values, predicted_values),\n",
    "                np.sqrt(metrics.mean_squared_error(true_values, predicted_values)),\n",
    "                metrics.r2_score(true_values, predicted_values)])\n",
    "\n",
    "\n",
    "lasso_metrics.index = ['Mean Absolute Error:', 'Mean Squared Error:', 'RMSE:', 'R2:']\n",
    "\n",
    "print(lasso_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularización Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = linear_model.Ridge(alpha=0.1)\n",
    "ridge.fit(X_train_transf, Y_train_numerical)\n",
    "Y_pred = ridge.predict(X_test_transf)\n",
    "\n",
    "true_values = Y_test_numerical\n",
    "predicted_values = Y_pred\n",
    "\n",
    "ridge_metrics = pd.Series([\n",
    "                metrics.mean_absolute_error(true_values, predicted_values), \n",
    "                metrics.mean_squared_error(true_values, predicted_values),\n",
    "                np.sqrt(metrics.mean_squared_error(true_values, predicted_values)),\n",
    "                metrics.r2_score(true_values, predicted_values)])\n",
    "\n",
    "\n",
    "ridge_metrics.index = ['Mean Absolute Error:', 'Mean Squared Error:', 'RMSE:', 'R2:']\n",
    "\n",
    "print(ridge_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 7 - PCA\n",
    "\n",
    "Grafiquemos la varianza explicada por 100, 50 y 30 componentes principales del dataset de train transformado con one hot encoding y StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_explained_variance(components_count, X):\n",
    "\n",
    "    model_pca = PCA(components_count).fit(X)\n",
    "\n",
    "    explained_variance = model_pca.explained_variance_ratio_\n",
    "\n",
    "    #print(explained_variance)\n",
    "\n",
    "    cumulative_explained_variance = np.cumsum(explained_variance)\n",
    "\n",
    "    #print(cumulative_explained_variance)\n",
    "\n",
    "    plt.plot(cumulative_explained_variance)\n",
    "    plt.xlabel('número de componentes')\n",
    "    plt.ylabel('% de varianza explicada');\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_explained_variance(components_count = 100, X = X_train_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_explained_variance(components_count = 50, X = X_train_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_explained_variance(components_count = 30, X = X_train_transf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 8 - Proyección sobre las componentes principales del conjunto de entrenamiento\n",
    "\n",
    "Construyamos un conjunto de entrenamiento y uno de test para una regresión lineal usando las primeras 30 componentes principales del conjunto de entrenamiento usado en la regresión lineal del ejercicio anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pca = PCA(30).fit(X_train_transf)\n",
    "X_train_PCA = model_pca.transform(X_train_transf)\n",
    "X_test_PCA = model_pca.transform(X_test_transf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 9 - Regresión lineal sobre componentes principales\n",
    "\n",
    "**6.1** Constuyamos un modelo de regresión lineal múltiple sobre los datasets de train y test usando como features la proyección sobre las componentes principales calculadas en el ejercicio anterior. ¿Qué supuesto podemos asegurar que se cumple usando las componentes principales como variables explicativas?\n",
    "\n",
    "**6.2** Construyamos otro modelo usando regularización Lasso sobre los mismos features que en 6.1\n",
    "\n",
    "**6.2** Construyamos un terecer modelo usando regularización Ridge sobre los mismos features que en 6.1\n",
    "\n",
    "Para los tres modelos calculemos:\n",
    "* mean_absolute_error\n",
    "* mean_squared_error\n",
    "* raiz cuadrada de mean_squared_error\n",
    "* r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cada una de las \"nuevas\" variables después de PCA son independientes entre sí. \n",
    "# los supuestos de un modelo lineal requieren que nuestras variables independientes sean independientes entre sí. \n",
    "# Si ajustamos un modelo de regresión lineal con estas \"nuevas\" variables, este supuesto necesariamente se cumplirá.\n",
    "\n",
    "linreg_pca = linear_model.LinearRegression()\n",
    "linreg_pca.fit(X_train_PCA, Y_train_numerical)\n",
    "# linear_fit\n",
    "Y_pred = linreg_pca.predict(X_test_PCA)\n",
    "\n",
    "true_values = Y_test_numerical\n",
    "predicted_values = Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_pca_metrics = pd.Series([\n",
    "                metrics.mean_absolute_error(true_values, predicted_values), \n",
    "                metrics.mean_squared_error(true_values, predicted_values),\n",
    "                np.sqrt(metrics.mean_squared_error(true_values, predicted_values)),\n",
    "                metrics.r2_score(true_values, predicted_values)])\n",
    "\n",
    "\n",
    "reg_pca_metrics.index = ['Mean Absolute Error:', 'Mean Squared Error:', 'RMSE:', 'R2:']\n",
    "\n",
    "print(reg_pca_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = linear_model.Lasso(alpha=0.1)\n",
    "lasso.fit(X_train_PCA, Y_train_numerical)\n",
    "Y_pred = lasso.predict(X_test_PCA)\n",
    "\n",
    "true_values = Y_test_numerical\n",
    "predicted_values = Y_pred\n",
    "\n",
    "lasso_pca_metrics = pd.Series([\n",
    "                metrics.mean_absolute_error(true_values, predicted_values), \n",
    "                metrics.mean_squared_error(true_values, predicted_values),\n",
    "                np.sqrt(metrics.mean_squared_error(true_values, predicted_values)),\n",
    "                metrics.r2_score(true_values, predicted_values)])\n",
    "\n",
    "\n",
    "lasso_pca_metrics.index = ['Mean Absolute Error:', 'Mean Squared Error:', 'RMSE:', 'R2:']\n",
    "\n",
    "print(lasso_pca_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = linear_model.Ridge(alpha=0.1)\n",
    "ridge.fit(X_train_PCA, Y_train_numerical)\n",
    "Y_pred = ridge.predict(X_test_PCA)\n",
    "\n",
    "true_values = Y_test_numerical\n",
    "predicted_values = Y_pred\n",
    "\n",
    "ridge_pca_metrics = pd.Series([\n",
    "                metrics.mean_absolute_error(true_values, predicted_values), \n",
    "                metrics.mean_squared_error(true_values, predicted_values),\n",
    "                np.sqrt(metrics.mean_squared_error(true_values, predicted_values)),\n",
    "                metrics.r2_score(true_values, predicted_values)])\n",
    "\n",
    "\n",
    "ridge_pca_metrics.index = ['Mean Absolute Error:', 'Mean Squared Error:', 'RMSE:', 'R2:']\n",
    "\n",
    "print(ridge_pca_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame([reg_metrics, lasso_metrics, ridge_metrics, \n",
    "                        reg_pca_metrics, lasso_pca_metrics, ridge_pca_metrics ])\n",
    "metrics.index = [\"regresion lineal\", \"lasso\", \"ridge\", \"pca - regresion lineal\", \"pca - lasso\", \"pca - ridge\"]\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que, para la regresión lineal múltiple, todas las métricas que obtenemos con el modelo entrenado con las componentes principales son mejores que las del modelo sin esta transformación.\n",
    "\n",
    "Con regularización de Lasso o Ridge no son tan evidentes las diferencias entre usar o no la proyección sobre las componenetes principales.\n",
    "\n",
    "Una ventaja de este segundo modelo es que usa 30 features mientras que el primero usa 280.\n",
    "\n",
    "Como ejercicio adicional, repitan los tres modelos usando en el ejercicio 5 \n",
    "`encoder = OneHotEncoder(categories = encoder_categories, sparse=False, drop=\"first\")`\n",
    "\n",
    "Y comparen estos nuevos resultados.\n",
    "\n",
    "**¿Qué significa que R2 sea negativo?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "https://www.kaggle.com/miguelangelnieto/pca-and-regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
